# Sample ADK Agents with Live Streaming

This repository provides a collection of sample agents built using the [Google Agent Development Kit (ADK)](https://google.github.io/adk-docs/). These agents demonstrate how to create robust, live, and multimodal interactions with end-users, incorporating audio, video, and text.

The foundation of this work is an adaptation of [Project Livewire](https://github.com/heiko-hotz/project-livewire/tree/main) by Heiko Hotz. Project Livewire is a modern multimodal chat solution that leverages Google's Gemini models and their Live Streaming API to enable real-time voice, text, and visual interactions.

![Sample UI](assets/ai-interview.png "UI for HR Interviewer Demo")

## Table of Contents

- [Overview](#overview)
  - [Sample Agent Use Cases](#sample-agent-use-cases)
  - [Key Features](#key-features)
  - [Agent Development Kit Integration](#agent-development-kit-integration)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Configure Environment Variables](#configure-environment-variables)
- [Database Setup (for AI Interviewer Agent)](#database-setup-for-ai-interviewer-agent)
  - [1. Create a Cloud SQL instance](#1-create-a-cloud-sql-instance)
  - [2. Create the interview table](#2-create-the-interview-table)
  - [3. Start the MCP Toolbox for Database server](#3-start-the-mcp-toolbox-for-database-server)
- [Quickstart](#quickstart)
  - [Option 1: Local Development](#option-1-local-development)
    - [1. Setup the Python virtual environment and install the dependencies](#1-setup-the-python-virtual-environment-and-install-the-dependencies)
    - [2. Database Setup (AI Interviewer Agent Only)](#2-database-setup-ai-interviewer-agent-only)
    - [3. Start the Backend Server](#3-start-the-backend-server)
    - [4. Start the Frontend Client](#4-start-the-frontend-client)
    - [5. Access the Application](#5-access-the-application)
    - [6. Test the Connection](#6-test-the-connection)
  - [Option 2. Deploy to Google Cloud Run](#option-2-deploy-to-google-cloud-run)
    - [1. Configure Environment Variables for Deployment](#1-configure-environment-variables-for-deployment)
    - [2. Database Setup (AI Interviewer Agent Only)](#2-database-setup-ai-interviewer-agent-only-1) 
    - [3. Run the Bash script to deploy agent backend](#3-run-the-bash-script-to-deploy-agent-backend)
    - [4. Update the backend URL in the client HTML file](#4-update-the-backend-url-in-the-client-html-file)
    - [5. Run the Bash script to deploy agent frontend](#5-run-the-bash-script-to-deploy-agent-frontend)
    - [6. Access the Application](#6-access-the-application)
    - [Troubleshooting Common Startup Issues](#troubleshooting-common-startup-issues)
- [Customizing and Extending Agents](#customizing-and-extending-agents)
- [Contributing](#contributing)
- [Support and Contact](#support-and-contact)
- [License](#license)

## Overview

This repo empowers developers to build robust, live Agents using [Google ADK](https://google.github.io/adk-docs/) that facilitate real-time multimodal interactions with end-users through audio, video, and text.

It is an adaptation of [Project Livewire](https://github.com/heiko-hotz/project-livewire/tree/main) created by Heiko Hotz, a modern multimodal chat solution that leverages Google's Gemini 2.0 and its Live Streaming API to enable real-time voice, text, and visual interactions.

### Sample Agent Use Cases

The adaptation is tested for 3 sample use cases:

-   **`AI Interviewer`**: This agent simulates a job interview. It takes a job description, candidate CV, and company profile as input. Users can interact with the agent through voice and text. The agent will ask questions relevant to the job role, evaluate responses, and provide a personalized interview experience. Its key functionality is to conduct dynamic, context-aware interviews.
-   **`RAG` (Retrieval Augmented Generation)**: This agent connects to a RAG data store defined in Vertex AI Search. It allows users to ask questions about the information contained within the data store. The agent retrieves relevant documents and uses them to generate informed answers. Users can expect to receive answers grounded in the provided knowledge base.
-   **`LLM Auditor`**: This agent acts as an automated fact-checking tool for responses generated by other Large Language Models (LLMs). It evaluates the factual accuracy of an LLM's output by comparing it against trusted sources or a predefined knowledge base. Users can expect this agent to help identify potential inaccuracies or biases in LLM-generated text, thereby enhancing the reliability of the information. It's an adaptation of this [ADK agent sample](https://github.com/google/adk-samples/tree/main/python/agents/llm-auditor).

### Key Features

-   Real-time audio, video (webcam and screen sharing), and text interaction with the Agent.

### Agent Development Kit Integration

-   Leverages the live streaming Agent capabilities of the Agent Development Kit.
-   Achieves low-latency responses with improved Time To First Token (TTFT).
-   Supports bidirectional streaming with interruption capabilities.

## Prerequisites

-   Python 3.8 or higher.
-   API keys for the Google Gemini API or access to Vertex AI on Google Cloud.

## Installation

To get started, clone this repository to your local machine:
```bash
git clone <repository-url> # Replace <repository-url> with the actual URL
cd <repository-name>     # Replace <repository-name> with the cloned directory name
```

## Configure Environment Variables

These environment variables are general prerequisites for both local development and cloud deployment.

First, navigate to the `server` directory:
```bash
cd server
```
Next, copy the example environment file `.env.example` to a new file named `.env`:
```bash
cp .env.example .env
```

Now, edit the `.env` file with your actual API keys and configuration details. You can use `nano` or your preferred text editor:
```bash
nano .env
```

The `.env.example` file outlines both required and optional environment variables. Ensure you set at least the following:

-   `LOG_LEVEL`: Defines the logging level (e.g., `INFO`, `DEBUG`). Defaults to `INFO`.
-   `DEMO_TYPE`: Specifies the agent demo to run (`hr`, `rag`, or `auditor`).
-   `GOOGLE_GENAI_USE_VERTEXAI`: Set to `1` to use Vertex AI, or `0` to use the Google AI development endpoint.
-   `GOOGLE_API_KEY`: Your Google API key (required if `GOOGLE_GENAI_USE_VERTEXAI` is `0`).
-   `GOOGLE_CLOUD_PROJECT_ID`: Your Google Cloud project ID (required if `GOOGLE_GENAI_USE_VERTEXAI` is `1`).
-   `GOOGLE_CLOUD_LOCATION`: Your Google Cloud region (e.g., `us-central1`) (required if `GOOGLE_GENAI_USE_VERTEXAI` is `1`).
-   `VAIS_DATASTORE_ID` **[Optional]**: Required only for the `RAG` agent. This is your Vertex AI Search Data Store ID. Refer to the [official documentation](https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search) for creation instructions.
-   `MCP_TOOLBOX_URL` **[Optional]**: Required only for the `AI Interviewer` agent. This URL points to the MCP (Multimodal Coordination Platform) Toolbox service, which the agent uses to interact with the Cloud SQL database for storing and retrieving interview data.
    -   For **local development**, the default value (`http://localhost:8082`) in `.env.example` is typically sufficient if you are running the MCP Toolbox server locally.
    -   For **remote deployments** (e.g., to Google Cloud Run), this URL is dynamically assigned by the deployment scripts (e.g., `s0_build_deploy_server.sh`). It will point to the deployed MCP Toolbox service in your cloud environment. You usually do not need to set this manually for remote deployments as the scripts handle this.

## Database Setup (for AI Interviewer Agent)

This section is **only required** if you are setting up the **`AI Interviewer`** agent. For other agents, you can skip these steps.

### 1. Create a Cloud SQL instance

Create a Cloud SQL for PostgreSQL instance. A common name is `live-agents-db-instance`. Follow the instructions in the [official Google Cloud documentation](https://cloud.google.com/sql/docs/postgres/create-instance).

### 2. Create the interview table

Connect to your Cloud SQL instance (e.g., using Cloud SQL Studio) and execute the following SQL DDL statement to create a table named `interview`.
Refer to [managing data using Cloud SQL Studio](https://cloud.google.com/sql/docs/postgres/manage-data-using-studio) for more help.

```sql
CREATE TABLE "public".interview (
    interview_id SERIAL PRIMARY KEY,
    interview_code VARCHAR NOT NULL,
    interview_date DATE,
    candidate_cv JSONB,
    job_description JSONB,
    evaluation JSONB
);
```

Optionally, populate the table with some sample data. You can provide the schema to a Generative AI model (like Gemini) and ask it to generate `INSERT` statements.

Below is an example `INSERT` statement:
```sql
INSERT INTO interview (interview_code, interview_date, candidate_cv, job_description)
VALUES(
  'ABC',
  CURRENT_DATE,
  '{
        "name": "Sami Sam",
        "email": "sami@example.com",
        "skills": [
            "Cloud Computing (AWS, Azure, GCP)",
            "Data Engineering (Spark, Hadoop, Kafka)",
            "Machine Learning (TensorFlow, PyTorch, Scikit-learn)",
            "AI Architecture"
        ],
        "experience": [
            {
                "title": "Senior Data and AI Architect",
                "company": "Tech Solutions Inc.",
                "years": "2018-Present",
                "description": "Designed and implemented scalable data and AI solutions for enterprise clients. Led a team of engineers in developing machine learning models and data pipelines. Provided technical leadership and guidance to clients on cloud adoption and data strategy."
            },
            {
                "title": "Data Engineer",
                "company": "Data Insights Corp.",
                "years": "2016-2018",
                "description": "Developed and maintained data pipelines for ingesting, processing, and storing large datasets. Implemented data quality checks and monitoring systems. Collaborated with data scientists to build machine learning models."
            }
        ],
        "education": [
            {
                "degree": "Master of Science in Data Science",
                "university": "University of California, Berkeley",
                "year": "2016"
            },
            {
                "degree": "Bachelor of Science in Computer Science",
                "university": "Cairo University",
                "year": "2014"
            }
        ],
        "languages": [
            "English (Native)",
            "Arabic (Native)",
            "French (Conversational)"
        ],
        "certifications": [
            "AWS Certified Solutions Architect - Professional",
            "Google Cloud Certified Professional Cloud Architect",
            "Microsoft Certified: Azure Solutions Architect Expert"
        ],
        "projects": [
            {
                "name": "Customer Churn Prediction",
                "description": "Developed a machine learning model to predict customer churn, resulting in a 15% reduction in churn rate."
            },
            {
                "name": "Sales Forecasting",
                "description": "Built a time series model to forecast sales for different product categories, improving forecast accuracy by 10%."
            }
        ]
    }',
     '{
        "location": "Riyadh, Saudi Arabia",
        "job_title": "Senior Data and AI Architect, Cloud Consulting (English, Arabic)",
        "level": "Advanced",
        "minimum_qualifications": "Bachelor''s degree or equivalent practical experience. 7 years of experience in delivery and developing customer-facing services Data and AI programs, leading engineers and aligning with business stakeholders and executive leadership. Ability to communicate in English and French fluently to support client relationship management in this region. Ability to travel 20% of the time as required.",
        "preferred_qualifications": "Experience implementing large-scale cloud or software projects in corporate environments. Knowledge in cloud architecture with experience across a range of enterprise use cases. Understanding of modern application migration and modernization approaches. Excellent organizational, problem-solving and influencing skills.",
        "about_the_job": "As a Data and AI Architect, you will work with Google’s customers on critical projects to help them transform their businesses. You will provide management, consulting, and technical aptitude to customer engagements while working with client executives and key technical leaders to deploy solutions via Google’s Cloud Platform. You will provide directional data strategy across people, process and technology. You will also work with key Google partners currently servicing top accounts to manage programs, deliver consulting services, and provide technical guidance and best practice expertise. Travel will be around 30% of client engagements. Google Cloud accelerates every organization’s ability to digitally transform its business and industry. We deliver enterprise-grade solutions that leverage Google’s cutting-edge technology, and tools that help developers build more sustainably. Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems.",
        "responsibilities": "Work with customer technical leads, client executives, and partners to architect, manage and deliver implementations of data and AI cloud solutions, becoming a trusted advisor to decision-makers throughout the engagement. Work with internal specialists, product, and engineering teams to consolidate best practices and lessons learned into thought leadership, methodologies, and solution. Interact with sales, partners, and customer technical stakeholders to manage project scope, priorities, deliverables, risks/issues, and timelines for successful client outcomes. Propose solution architectures and manage the deployment of cloud based Data and AI solutions according to customer requirements and implementation best practices, support consultancy pre sales teams via architectural discussions and design workshops."
    }'
);
```

### 3. Start the MCP Toolbox for Database server

The MCP Toolbox is used by the `AI Interviewer` agent to interact with the database. The version installed by default from this repository is for Linux amd64 and is located in `server/mcp_toolbox/`.

If you are using a different operating system or architecture for local development, you may need to install a different version of the MCP Toolbox for Databases. Follow the "Installing the server" section [in the GenAI Toolbox GitHub repository](https://github.com/googleapis/genai-toolbox). You can find available releases [on this page](https://github.com/googleapis/genai-toolbox/releases).

Before starting the server, update the `mcp_toolbox/tools.yaml` file with your Cloud SQL instance name and the table name (`interview`, if you used the name from the previous step).

Start the MCP server from the `server` directory:
```bash
cd server # if not already in the server directory
python mcp_toolbox/server.py
```
Ensure you are in the `server` directory when running the above command. The MCP server typically runs on `localhost:8082`.

## Quickstart

Choose one of the following options to run the application:

### Option 1: Local Development

Follow these steps to run the application on your local machine:

#### 1. Setup the Python virtual environment and install the dependencies

From the **root directory** of the repository, execute the following commands to create and activate a Python virtual environment:
```bash
python3 -m venv venv
source venv/bin/activate
```
Then, navigate to the `server` directory and install the Python dependencies:
```bash
cd server
pip install -r requirements.txt
# It's recommended to stay in the 'server' directory for the subsequent backend server startup step.
```

#### 2. Database Setup (AI Interviewer Agent Only)

If you are setting up the **`AI Interviewer`** Agent, ensure you have completed all steps in the [Database Setup (for AI Interviewer Agent)](#database-setup-for-ai-interviewer-agent) section. This typically involves database creation and table setup, which are external to this local application setup flow but are prerequisites for the agent to function.

#### 3. Start the Backend Server

If you are not already in the `server` directory, navigate to it. Then, start the main backend server:
```bash
# Assuming you are in the 'server' directory:
python server.py
# If in root, then: 
# cd server
# python server.py
```
The backend server will typically start on `localhost:8081`.

#### 4. Start the Frontend Client

Open a **new terminal window or tab**. Navigate to the `client` directory from the repository root:
```bash
cd client
```
Start a simple HTTP server to serve the frontend files:
```bash
python -m http.server 8000
```

#### 5. Access the Application

Open your web browser and navigate to the development UI:
`http://localhost:8000/index.html`

#### 6. Test the Connection

1.  Open your browser's developer tools (usually by pressing `F12`).
2.  Check the console for any connection errors.
3.  Try sending a test message through the interface.
4.  Verify that the WebSocket connection is established and active.

### Option 2. Deploy to Google Cloud Run

This guide assumes you have the Google Cloud SDK (`gcloud` CLI) installed and configured with appropriate permissions for your Google Cloud project.

#### 1. Configure Environment Variables for Deployment
Open the `s0_build_deploy_agent.sh` script, located in the root folder of the repository. Edit the following environment variables at the top of the script:

```bash
export PROJECT_ID='your-gcp-project-id'         # Replace with your Project ID
export PROJECT_NUMBER='your-gcp-project-number' # Replace with your Project Number
export LOCATION='us-central1'                   # Or your preferred Google Cloud region
export AGENTS_BUCKET='your-agents-bucket-name'  # Replace with a unique bucket name
export DB_INSTANCE_NAME='live-agents-db-instance' # Or your Cloud SQL instance name
export DEMO_TYPE='hr'                           # 'hr', 'rag', or 'auditor'
```

#### 2. Database Setup (AI Interviewer Agent Only)

If you are deploying the **`AI Interviewer`** Agent, ensure you have completed the steps in the [Database Setup (for AI Interviewer Agent)](#database-setup-for-ai-interviewer-agent) section. Your Cloud SQL instance must be correctly configured and accessible by the Cloud Run environment. This might involve configuring VPC connectors or public IP access with strong passwords and SSL, depending on your setup.

#### 3. Run the Bash script to deploy agent backend
From the **root directory** of the repository, execute the deployment script for the backend server:
```bash
sh s0_build_deploy_server.sh
```
This script will build and deploy the agent backend service to Google Cloud Run. It will also deploy the MCP Toolbox if the `DEMO_TYPE` is `hr`.

#### 4. Update the backend URL in the client HTML file
After the backend deployment is successful, the script will output the URL of the deployed backend service. This URL is needed to configure the frontend client.

If you missed the URL, you can retrieve it using `gcloud`. First, ensure the `DEMO_TYPE` and `LOCATION` environment variables are set in your terminal session, matching those used for deployment:
```bash
export DEMO_TYPE='hr' # Or 'rag', 'auditor'
export LOCATION='us-central1' # Or your deployment region
```
Then, run the command:
```bash
BACKEND_URL=$(gcloud run services describe live-agent-backend-${DEMO_TYPE} --platform managed --region ${LOCATION} --format 'value(status.url)')
echo "Backend URL: ${BACKEND_URL}"
```

Open the `client/src/index.html` file. Locate the `GeminiAPI` instantiation (around Line 70). Update it to use the `BACKEND_URL` you retrieved. Remember to use the `wss` (WebSocket Secure) protocol for deployed services.

Example:
```javascript
   // const api = new GeminiAPI(); // Default for local: 'ws://localhost:8081'
   const api = new GeminiAPI('wss://your-deployed-backend-url.a.run.app'); // Replace with your actual backend URL
```

#### 5. Run the Bash script to deploy agent frontend
From the **root directory** of the repository, deploy the frontend client to Cloud Run:
```bash
sh s0_build_deploy_client.sh
```

#### 6. Access the Application
Once the frontend deployment is complete, the script will output its URL. You can also retrieve it using `gcloud`:
```bash
export DEMO_TYPE='hr' # Ensure this is set to your deployed agent type
FRONTEND_URL=$(gcloud run services describe live-agent-ui-${DEMO_TYPE} --platform managed --region ${LOCATION:-us-central1} --format 'value(status.url)')
echo "Frontend URL: ${FRONTEND_URL}"
```
Access this `FRONTEND_URL` in your web browser to use the application.

#### Troubleshooting Common Startup Issues
-   **Cloud Run Deployment Issues:**
    -   Check Cloud Build logs for build errors.
    -   Ensure the service account used by Cloud Run (usually the default Compute Engine service account, or a custom one you configured) has necessary permissions:
        -   `Cloud Run Invoker` for public services, or appropriate permissions for private services.
        -   `Secret Manager Secret Accessor` if using secrets.
        -   `Cloud SQL Client` if connecting to Cloud SQL.
        -   Permissions to access any other Google Cloud services your agent might use.
-   **Secret Manager Access Errors:**
    -   Verify that the Cloud Run service's runtime service account has the `Secret Manager Secret Accessor` role for the specific secrets it needs to access.
-   **Connectivity Issues:**
    -   **Local to Cloud SQL:** Ensure your local machine's IP is authorized to connect to your Cloud SQL instance, or use the Cloud SQL Auth Proxy.
    -   **Cloud Run to Cloud SQL:** Ensure you have configured either a Public IP connection (with strong credentials and SSL) or a Private IP connection using a Serverless VPC Access connector for your Cloud Run service to reach your Cloud SQL instance.
    -   **Frontend to Backend:** Double-check that the backend URL in `client/src/index.html` is correct and uses `wss://`.
    -   For basic testing, ensure your Cloud Run services allow unauthenticated invocations. For production, configure appropriate authentication.

## Customizing and Extending Agents

The behavior of each agent is primarily defined by its system instructions and the tools it's configured to use. You can customize and extend the agents in the following ways:

*   **System Instructions:** Modify the `system-instructions.txt` file within the respective agent's configuration directory (e.g., `server/config/hr/system-instructions.txt` for the AI Interviewer) to change its core persona, objectives, and response guidelines.
*   **Tools:** Agents use tools to perform specific actions (e.g., database lookups for the AI Interviewer, web searches for a RAG agent).
    *   Modify existing tool configurations, typically found in YAML files or Python scripts within the agent's configuration or a shared tools directory.
    *   Add new tools by defining their functionality and integrating them into the agent's processing logic.
*   **Agent Logic:** For deeper modifications, explore the agent-specific Python files in the `server/core/agents/` directory (e.g., `server/core/agents/hr_agent.py`). This is where the core interaction flow, tool invocation, and response generation logic for each agent reside.

By adjusting these components, you can tailor the agents to different use cases, integrate new data sources, or add entirely new capabilities.

## Contributing

Contributions to this project are welcome! If you have improvements, bug fixes, or new features you'd like to share, please follow these general guidelines:

1.  **Fork the Repository:** Create your own fork of the project on GitHub.
2.  **Create a Branch:** Make a new branch in your fork for your specific feature or bug fix (e.g., `feature/new-tool` or `fix/login-bug`).
3.  **Commit Your Changes:** Write clear, concise commit messages that explain the purpose of your changes.
4.  **Test Your Code:** If applicable, ensure your changes are well-tested and do not break existing functionality.
5.  **Submit a Pull Request:** Open a pull request from your branch to the main repository's `main` (or `master`) branch. Provide a clear description of your changes in the pull request.

We appreciate your contributions to making these sample agents even better!

## Support and Contact

If you encounter any issues, have questions, or want to suggest improvements, please open an issue on the GitHub repository. This is the primary way to communicate with the maintainers and the community.

### License

This project is licensed under the MIT License. See the `LICENSE` file for details.

